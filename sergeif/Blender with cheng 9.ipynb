{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk('../blend/'):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "\n",
    "ff = []\n",
    "for (dirpath, dirnames, filenames) in walk('../skolbachev/'):\n",
    "    for d in dirnames:\n",
    "        for (dirpath, dirnames2, filenames) in walk('../skolbachev/'+d):\n",
    "            for qf in filenames:\n",
    "                ff.append('../skolbachev/'+d+'/'+qf)\n",
    "                \n",
    "chen_sol = pd.read_csv('../cheng/ensemble/9/gru.info.dsfu.lower_model.ckpt-30.00-67290.valid').sort_values('id').reset_index(drop=True)                \n",
    "chen_sol_ids = chen_sol['id'].values\n",
    "\n",
    "fchen = []\n",
    "for (dirpath, dirnames, filenames) in walk('../cheng/ensemble/9'):\n",
    "    fchen.extend([q for q in filenames if q.endswith('.valid')])\n",
    "    break \n",
    "\n",
    "train_idx = pd.read_csv('../input/train.csv')['id'].values\n",
    "train = pd.read_csv('../input/train.csv').sort_values('id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_att 0.9886094397266466\n",
      "2ycnn 0.9868049386439646\n",
      "4gru 0.9873563272245937\n",
      "5cnn 0.9844012138936078\n",
      "att 0.987329988998776\n",
      "char_rnn 0.9889906618421405\n",
      "cnnb 0.9837541668676183\n",
      "conv2dm 0.9859917031900279\n",
      "grucnn 0.9892953583553575\n",
      "grucnn_fl 0.9884734455628387\n",
      "grucnn_fl3 0.9900106258551316\n",
      "grucnn_fl4 0.9897142748398743\n",
      "lr 0.9864988837790026\n",
      "nbsvm 0.9860737665889984\n",
      "olgbm 0.980899519706738\n",
      "ryanc2d 0.9856651156122117\n",
      "ryangru 0.9868306224815333\n",
      "wordbatch2 0.9861707682227453\n",
      "ycnn 0.983265458485085\n",
      "sk0 0.9908441370482972\n",
      "sk1 0.9911680228358426\n",
      "sk2 0.9900051360335094\n",
      "sk3 0.9900499525360588\n",
      "sk4 0.9903586034155518\n",
      "sk5 0.9893902526807571\n",
      "sk6 0.9900944701136121\n",
      "sk7 0.9895366459417468\n",
      "sk8 0.9906284384471021\n",
      "sk9 0.9905225954504444\n",
      "sk10 0.9899603886696958\n",
      "chen0 0.991999076873736\n",
      "chen1 0.9924723797956659\n",
      "chen2 0.9919231861259981\n",
      "chen3 0.9923791534572223\n",
      "chen4 0.9919445448270507\n",
      "chen5 0.9773253916780882\n",
      "chen6 0.9918822328410242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "train = train.loc[train['id'].isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "\n",
    "oofs = []\n",
    "onms = []\n",
    "\n",
    "train_files = [q for q in f if q.startswith('train')]\n",
    "for q in train_files:\n",
    "    nm = q[6:-4]\n",
    "    nf = pd.read_csv('../blend/'+q)\n",
    "    nf = nf.loc[nf.id.isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "    for c in cols:\n",
    "        if 'identity_hate' in nf.columns:\n",
    "            nf[c] = minmax_scale(nf[c])\n",
    "        else:\n",
    "            nf[c] = minmax_scale(nf[c+'_oof'])\n",
    "            nf.drop([c+'_oof'],axis=1,inplace=True)\n",
    "        #print(nm,c,roc_auc_score(train[c],nf[c]))\n",
    "    if (nf.columns.tolist().index('id')==0):\n",
    "        nf.columns = ['id'] + [nm+'_' + q for q in cols]\n",
    "    else:\n",
    "        nf.columns = [nm+'_' + q for q in cols] + ['id']\n",
    "    print(nm, roc_auc_score(train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']],nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "    onms.append(nm)\n",
    "    oofs.append(nf)\n",
    "    \n",
    "sk_train = [q for q in ff if not q.endswith('test_X_pred.npy')]\n",
    "suf = 'sk'\n",
    "i = 0\n",
    "for q in sk_train:\n",
    "    nf = pd.DataFrame(np.load(q))\n",
    "    nm = suf+str(i)\n",
    "    nf.columns = [nm+'_'+q for q in cols]\n",
    "    nf['id'] = train_idx\n",
    "    nf = nf.loc[nf.id.isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "    for c in cols:\n",
    "        nf[nm+'_'+c] = minmax_scale(nf[nm+'_'+c])\n",
    "    print(nm, roc_auc_score(train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']],nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "    onms.append(nm)\n",
    "    oofs.append(nf)\n",
    "    i = i + 1\n",
    "    \n",
    "suf = 'chen'\n",
    "i = 0\n",
    "for q in fchen:\n",
    "    nf = pd.read_csv('../cheng/ensemble/9/'+q)\n",
    "    nm = suf+str(i)\n",
    "    nf.columns = ['id'] + [nm+'_'+q for q in cols]\n",
    "    nf = nf.sort_values('id').reset_index(drop=True)\n",
    "    for c in cols:\n",
    "        nf[nm+'_'+c] = minmax_scale(nf[nm+'_'+c])\n",
    "    try:\n",
    "        print(nm, roc_auc_score(\n",
    "                    train[cols],\n",
    "                    nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "        onms.append(nm)\n",
    "        oofs.append(nf)\n",
    "    except:\n",
    "        nf = nf.loc[nf['id'] != '0',:].reset_index(drop=True)\n",
    "        print(nm, roc_auc_score(\n",
    "                    train[cols],\n",
    "                    nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "        onms.append(nm)\n",
    "        oofs.append(nf)\n",
    "        pass\n",
    "    i = i + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "train = train.loc[train['id'].isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "for o in oofs:\n",
    "    train = train.merge(o, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_att','2ycnn','4gru','5cnn','att','char_rnn','cnnb','conv2dm','grucnn','grucnn_fl','grucnn_fl3','grucnn_fl4','lr','nbsvm','olgbm','ryanc2d','ryangru','wordbatch2','ycnn','sk0','sk1','sk2','sk3','sk4','sk5','sk6','sk7','sk8','sk9','sk10','chen0','chen1','chen2','chen3','chen4','chen5','chen6\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\',\\''.join(onms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate', '_att_toxic', '_att_severe_toxic',\n",
       "       ...\n",
       "       'chen5_obscene', 'chen5_threat', 'chen5_insult', 'chen5_identity_hate',\n",
       "       'chen6_toxic', 'chen6_severe_toxic', 'chen6_obscene', 'chen6_threat',\n",
       "       'chen6_insult', 'chen6_identity_hate'],\n",
       "      dtype='object', length=230)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_cols = ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for c in cols:\n",
    "    y = train[c]\n",
    "    q = train.drop(orig_cols, axis=1)\n",
    "    scores[c] = []\n",
    "    for n in onms:\n",
    "        w = roc_auc_score(y,train[n+'_'+c])\n",
    "        scores[c].append(w)\n",
    "        #print(n,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_nms(nms,c):\n",
    "    scores = {}\n",
    "    y = train[c]\n",
    "    q = train.drop(orig_cols, axis=1)\n",
    "    scores[c] = []\n",
    "    for n in nms:\n",
    "        w = roc_auc_score(y,train[n+'_'+c])\n",
    "        scores[c].append(w)        \n",
    "    p = []\n",
    "    ws = scores[c]\n",
    "    y = train[c]\n",
    "    pred = 0\n",
    "    i = 0\n",
    "    for n in nms:\n",
    "        pred += ((ws[i]-np.min(ws))/(np.max(ws)-np.min(ws))+0.01)*(minmax_scale(train[n+'_'+c],feature_range=(0.000001, 0.9999999)))\n",
    "        i = i + 1\n",
    "    p.append(roc_auc_score(y,pred))\n",
    "    return np.mean(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic 0.9903198606082227\n",
      "severe_toxic 0.992917088394062\n",
      "obscene 0.995752926720944\n",
      "threat 0.9978916268544128\n",
      "insult 0.9908479226321134\n",
      "identity_hate 0.9946680508129225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9937329126704463"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sets = {}\n",
    "for c in cols:\n",
    "    bst = evaluate_nms(onms,c)\n",
    "    best_set = onms\n",
    "    while True:\n",
    "        d = {}\n",
    "        bst_j = ''\n",
    "        for j in best_set:\n",
    "            nms = list(set(best_set) - set([j]))\n",
    "            d[j] = evaluate_nms(nms,c)\n",
    "            if d[j] > bst:\n",
    "                bst = d[j]\n",
    "                bst_j = j\n",
    "        if bst_j == '':\n",
    "            break\n",
    "        best_set = list(set(best_set) - set([bst_j]))\n",
    "    best_sets[c] = best_set.copy()\n",
    "    \n",
    "ppp = []\n",
    "for c in cols:\n",
    "    ppp.append(evaluate_nms(best_sets[c],c))\n",
    "    print(c, evaluate_nms(best_sets[c],c))\n",
    "np.mean(ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "train_files = [q for q in f if q.startswith('test')]\n",
    "for q in train_files:\n",
    "    nf = pd.read_csv('../blend/'+q)\n",
    "    for c in cols:\n",
    "        nf[c] = minmax_scale(nf[c])\n",
    "    preds.append(nf)\n",
    "    \n",
    "sk_train = [q for q in ff if q.endswith('test_X_pred.npy')]\n",
    "suf = 'sk'\n",
    "i = 0\n",
    "for q in sk_train:\n",
    "    nf = pd.DataFrame(np.mean(np.load(q),axis=0))\n",
    "    nf.columns = cols\n",
    "    for c in cols:\n",
    "        nf[c] = minmax_scale(nf[c])\n",
    "    preds.append(nf)\n",
    "    i = i + 1\n",
    "\n",
    "suf = 'chen'\n",
    "i = 0\n",
    "for q in fchen:\n",
    "    nf = pd.read_csv('../cheng/ensemble/9/'+q.replace('.valid','.infer')).sort_values('id').reset_index(drop=True)\n",
    "    nm = suf+str(i)\n",
    "    if nm not in onms:\n",
    "        print(nm)\n",
    "        i = i + 1\n",
    "        continue\n",
    "    for c in cols:\n",
    "        nf[c] = minmax_scale(nf[c])\n",
    "    preds.append(nf)\n",
    "    i = i + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.978505</td>\n",
       "      <td>0.477383</td>\n",
       "      <td>0.981480</td>\n",
       "      <td>0.191414</td>\n",
       "      <td>0.957730</td>\n",
       "      <td>0.522438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.001668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.978505      0.477383  0.981480  0.191414  0.957730   \n",
       "1  0000247867823ef7  0.005773      0.002361  0.000155  0.001484  0.000181   \n",
       "2  00013b17ad220c46  0.007483      0.001864  0.000548  0.002826  0.000228   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.522438  \n",
       "1       0.001668  \n",
       "2       0.001077  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "for c in cols:\n",
    "    sub[c] = 0\n",
    "    y = train[c]\n",
    "    ws = []\n",
    "    for n in best_sets[c]:\n",
    "        w = roc_auc_score(y,train[n+'_'+c])\n",
    "        ws.append(w)\n",
    "    k = 0\n",
    "    for n in best_sets[c]:\n",
    "        j = onms.index(n)\n",
    "        sub[c] += ((ws[k]-np.min(ws))/(np.max(ws)-np.min(ws))+0.01) * preds[j][c]\n",
    "        k = k + 1\n",
    "    sub[c] = minmax_scale(sub[c])\n",
    "sub.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('weighted_blend_37models_9.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
