{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk('../blend/'):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "\n",
    "ff = []\n",
    "for (dirpath, dirnames, filenames) in walk('../skolbachev/'):\n",
    "    for d in dirnames:\n",
    "        for (dirpath, dirnames2, filenames) in walk('../skolbachev/'+d):\n",
    "            for qf in filenames:\n",
    "                ff.append('../skolbachev/'+d+'/'+qf)\n",
    "                \n",
    "chen_sol = pd.read_csv('../cheng/ensemble/0/gru.info.dsfu.lower_model.ckpt-30.00-67290.valid').sort_values('id').reset_index(drop=True)                \n",
    "chen_sol_ids = chen_sol['id'].values\n",
    "\n",
    "fchen = []\n",
    "for (dirpath, dirnames, filenames) in walk('../cheng/ensemble/0'):\n",
    "    fchen.extend([q for q in filenames if q.endswith('.valid')])\n",
    "    break \n",
    "\n",
    "train_idx = pd.read_csv('../input/train.csv')['id'].values\n",
    "train = pd.read_csv('../input/train.csv').sort_values('id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_att 0.9892338966689888\n",
      "2ycnn 0.9872937963952745\n",
      "4gru 0.9877258892489956\n",
      "5cnn 0.985520176335636\n",
      "att 0.9888112247294701\n",
      "char_rnn 0.9897314616407745\n",
      "cnnb 0.9857916863176316\n",
      "conv2dm 0.9875904540822394\n",
      "grucnn 0.9897345772896817\n",
      "grucnn_fl 0.9878977922949453\n",
      "grucnn_fl3 0.9898714559818971\n",
      "grucnn_fl4 0.9903736267850268\n",
      "lr 0.9860067545162373\n",
      "nbsvm 0.9836559703994577\n",
      "olgbm 0.9790489091160021\n",
      "ryanc2d 0.9866048861100657\n",
      "ryangru 0.9868070243989284\n",
      "wordbatch2 0.9871980403733103\n",
      "ycnn 0.9840618188201989\n",
      "sk0 0.9906244245956127\n",
      "sk1 0.9912209161416837\n",
      "sk2 0.990944715254443\n",
      "sk3 0.9894623577708314\n",
      "sk4 0.9901429247165856\n",
      "sk5 0.9899643578839217\n",
      "sk6 0.9909914340810507\n",
      "sk7 0.9908666779378529\n",
      "sk8 0.9912480419053993\n",
      "sk9 0.990022987205814\n",
      "sk10 0.9908662683180162\n",
      "chen0 0.9923749948338313\n",
      "chen1 0.9918290790792544\n",
      "chen2 0.9921734236841733\n",
      "chen3 0.9924083080832201\n",
      "chen4 0.9919758658936239\n",
      "chen5 0.983998910001041\n",
      "chen6 0.9920516765656857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "train = train.loc[train['id'].isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "\n",
    "oofs = []\n",
    "onms = []\n",
    "\n",
    "train_files = [q for q in f if q.startswith('train')]\n",
    "for q in train_files:\n",
    "    nm = q[6:-4]\n",
    "    nf = pd.read_csv('../blend/'+q)\n",
    "    nf = nf.loc[nf.id.isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "    for c in cols:\n",
    "        if 'identity_hate' in nf.columns:\n",
    "            nf[c] = minmax_scale(nf[c])\n",
    "        else:\n",
    "            nf[c] = minmax_scale(nf[c+'_oof'])\n",
    "            nf.drop([c+'_oof'],axis=1,inplace=True)\n",
    "        #print(nm,c,roc_auc_score(train[c],nf[c]))\n",
    "    if (nf.columns.tolist().index('id')==0):\n",
    "        nf.columns = ['id'] + [nm+'_' + q for q in cols]\n",
    "    else:\n",
    "        nf.columns = [nm+'_' + q for q in cols] + ['id']\n",
    "    print(nm, roc_auc_score(train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']],nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "    onms.append(nm)\n",
    "    oofs.append(nf)\n",
    "    \n",
    "sk_train = [q for q in ff if not q.endswith('test_X_pred.npy')]\n",
    "suf = 'sk'\n",
    "i = 0\n",
    "for q in sk_train:\n",
    "    nf = pd.DataFrame(np.load(q))\n",
    "    nm = suf+str(i)\n",
    "    nf.columns = [nm+'_'+q for q in cols]\n",
    "    nf['id'] = train_idx\n",
    "    nf = nf.loc[nf.id.isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "    for c in cols:\n",
    "        nf[nm+'_'+c] = minmax_scale(nf[nm+'_'+c])\n",
    "    print(nm, roc_auc_score(train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']],nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "    onms.append(nm)\n",
    "    oofs.append(nf)\n",
    "    i = i + 1\n",
    "    \n",
    "suf = 'chen'\n",
    "i = 0\n",
    "for q in fchen:\n",
    "    nf = pd.read_csv('../cheng/ensemble/0/'+q)\n",
    "    nm = suf+str(i)\n",
    "    nf.columns = ['id'] + [nm+'_'+q for q in cols]\n",
    "    nf = nf.sort_values('id').reset_index(drop=True)\n",
    "    for c in cols:\n",
    "        nf[nm+'_'+c] = minmax_scale(nf[nm+'_'+c])\n",
    "    try:\n",
    "        print(nm, roc_auc_score(\n",
    "                    train[cols],\n",
    "                    nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "        onms.append(nm)\n",
    "        oofs.append(nf)\n",
    "    except:\n",
    "        nf = nf.loc[nf['id'] != '0',:].reset_index(drop=True)\n",
    "        print(nm, roc_auc_score(\n",
    "                    train[cols],\n",
    "                    nf[[nm+'_toxic',nm+'_severe_toxic',nm+'_obscene',nm+'_threat',nm+'_insult',nm+'_identity_hate']]))\n",
    "        onms.append(nm)\n",
    "        oofs.append(nf)\n",
    "        pass\n",
    "    i = i + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "train = train.loc[train['id'].isin(chen_sol_ids),:].sort_values('id').reset_index(drop=True)\n",
    "for o in oofs:\n",
    "    train = train.merge(o, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_att','2ycnn','4gru','5cnn','att','char_rnn','cnnb','conv2dm','grucnn','grucnn_fl','grucnn_fl3','grucnn_fl4','lr','nbsvm','olgbm','ryanc2d','ryangru','wordbatch2','ycnn','sk0','sk1','sk2','sk3','sk4','sk5','sk6','sk7','sk8','sk9','sk10','chen0','chen1','chen2','chen3','chen4','chen5','chen6\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\',\\''.join(onms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate', '_att_toxic', '_att_severe_toxic',\n",
       "       ...\n",
       "       'chen5_obscene', 'chen5_threat', 'chen5_insult', 'chen5_identity_hate',\n",
       "       'chen6_toxic', 'chen6_severe_toxic', 'chen6_obscene', 'chen6_threat',\n",
       "       'chen6_insult', 'chen6_identity_hate'],\n",
       "      dtype='object', length=230)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_cols = ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for c in cols:\n",
    "    y = train[c]\n",
    "    q = train.drop(orig_cols, axis=1)\n",
    "    scores[c] = []\n",
    "    for n in onms:\n",
    "        w = roc_auc_score(y,train[n+'_'+c])\n",
    "        scores[c].append(w)\n",
    "        #print(n,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_nms(nms,c):\n",
    "    scores = {}\n",
    "    y = train[c]\n",
    "    q = train.drop(orig_cols, axis=1)\n",
    "    scores[c] = []\n",
    "    for n in nms:\n",
    "        w = roc_auc_score(y,train[n+'_'+c])\n",
    "        scores[c].append(w)        \n",
    "    p = []\n",
    "    ws = scores[c]\n",
    "    y = train[c]\n",
    "    pred = 0\n",
    "    i = 0\n",
    "    for n in nms:\n",
    "        pred += ((ws[i]-np.min(ws))/(np.max(ws)-np.min(ws))+0.01)*(minmax_scale(train[n+'_'+c],feature_range=(0.000001, 0.9999999)))\n",
    "        i = i + 1\n",
    "    p.append(roc_auc_score(y,pred))\n",
    "    return np.mean(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic 0.9904497862245549\n",
      "severe_toxic 0.993876212110295\n",
      "obscene 0.9960970083435621\n",
      "threat 0.9941063904336656\n",
      "insult 0.9909078420206017\n",
      "identity_hate 0.9940125563561286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.993241632581468"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sets = {}\n",
    "for c in cols:\n",
    "    bst = evaluate_nms(onms,c)\n",
    "    best_set = onms\n",
    "    while True:\n",
    "        d = {}\n",
    "        bst_j = ''\n",
    "        for j in best_set:\n",
    "            nms = list(set(best_set) - set([j]))\n",
    "            d[j] = evaluate_nms(nms,c)\n",
    "            if d[j] > bst:\n",
    "                bst = d[j]\n",
    "                bst_j = j\n",
    "        if bst_j == '':\n",
    "            break\n",
    "        best_set = list(set(best_set) - set([bst_j]))\n",
    "    best_sets[c] = best_set.copy()\n",
    "    \n",
    "ppp = []\n",
    "for c in cols:\n",
    "    ppp.append(evaluate_nms(best_sets[c],c))\n",
    "    print(c, evaluate_nms(best_sets[c],c))\n",
    "np.mean(ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "train_files = [q for q in f if q.startswith('test')]\n",
    "for q in train_files:\n",
    "    nf = pd.read_csv('../blend/'+q)\n",
    "    for c in cols:\n",
    "        nf[c] = minmax_scale(nf[c])\n",
    "    preds.append(nf)\n",
    "    \n",
    "sk_train = [q for q in ff if q.endswith('test_X_pred.npy')]\n",
    "suf = 'sk'\n",
    "i = 0\n",
    "for q in sk_train:\n",
    "    nf = pd.DataFrame(np.mean(np.load(q),axis=0))\n",
    "    nf.columns = cols\n",
    "    for c in cols:\n",
    "        nf[c] = minmax_scale(nf[c])\n",
    "    preds.append(nf)\n",
    "    i = i + 1\n",
    "\n",
    "suf = 'chen'\n",
    "i = 0\n",
    "for q in fchen:\n",
    "    nf = pd.read_csv('../cheng/ensemble/0/'+q.replace('.valid','.infer')).sort_values('id').reset_index(drop=True)\n",
    "    nm = suf+str(i)\n",
    "    if nm not in onms:\n",
    "        print(nm)\n",
    "        i = i + 1\n",
    "        continue\n",
    "    for c in cols:\n",
    "        nf[c] = minmax_scale(nf[c])\n",
    "    preds.append(nf)\n",
    "    i = i + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.969993</td>\n",
       "      <td>0.481172</td>\n",
       "      <td>0.919635</td>\n",
       "      <td>0.129908</td>\n",
       "      <td>0.939999</td>\n",
       "      <td>0.573190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.001344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.969993      0.481172  0.919635  0.129908  0.939999   \n",
       "1  0000247867823ef7  0.008567      0.000051  0.008214  0.010214  0.006135   \n",
       "2  00013b17ad220c46  0.011356      0.000046  0.006263  0.011426  0.005055   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.573190  \n",
       "1       0.000736  \n",
       "2       0.001344  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "for c in cols:\n",
    "    sub[c] = 0\n",
    "    y = train[c]\n",
    "    ws = []\n",
    "    for n in best_sets[c]:\n",
    "        w = roc_auc_score(y,train[n+'_'+c])\n",
    "        ws.append(w)\n",
    "    k = 0\n",
    "    for n in best_sets[c]:\n",
    "        j = onms.index(n)\n",
    "        sub[c] += ((ws[k]-np.min(ws))/(np.max(ws)-np.min(ws))+0.01) * preds[j][c]\n",
    "        k = k + 1\n",
    "    sub[c] = minmax_scale(sub[c])\n",
    "sub.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('weighted_blend_37models_0.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
