{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:45:15.770872Z",
     "start_time": "2018-03-08T12:45:14.577627Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7961730\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# import local_utils; importlib.reload(local_utils)\n",
    "from local_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:45:19.872172Z",
     "start_time": "2018-03-08T12:45:15.771892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "\n",
      "Processed:\n",
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now. \n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "ids, comments, Y, test_ids, test_comments, inx2label, label2inx = load_data()\n",
    "Y_wblank = np.concatenate([Y, np.expand_dims((~Y.any(axis=1)).astype(int), 1)], axis=1)\n",
    "print(\"Original:\\n\" + comments[0])\n",
    "print()\n",
    "\n",
    "comments = Parallel(n_jobs=cpu_cores)(delayed(preprocess)(text, False) for text in comments)\n",
    "test_comments = Parallel(n_jobs=cpu_cores)(delayed(preprocess)(text, False) for text in test_comments)\n",
    "print(\"Processed:\\n\" + comments[0])\n",
    "\n",
    "# comments_fr, comments_de, comments_es = load_augmented_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:45:25.007981Z",
     "start_time": "2018-03-08T12:45:19.874692Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "vectors_ft, inx2word_ft, word2inx_ft = load_embs(embs_name='crawl-300d-2M')\n",
    "vectors_gl, inx2word_gl, word2inx_gl = load_embs(embs_name='glove-300d-840B')\n",
    "vectors_gl_tw, inx2word_gl_tw, word2inx_gl_tw = load_embs(embs_name='glove-twitter-200d-27B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:45:25.010627Z",
     "start_time": "2018-03-08T12:45:25.009063Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tokenize(text):\n",
    "#     return glove_twitter_tokenizer.tokenize(text, word2inx)\n",
    "\n",
    "# docs = Parallel(n_jobs=cpu_cores)(delayed(tokenize)(text) for text in comments + test_comments)\n",
    "# pickle.dump(docs, open('data/tokenized_twitter_comments.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:45:30.388275Z",
     "start_time": "2018-03-08T12:45:25.011525Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = pickle.load(open('data/tokenized_comments.pkl', 'rb'))\n",
    "docs_tw = pickle.load(open('data/tokenized_twitter_comments.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:47:21.522341Z",
     "start_time": "2018-03-08T12:45:30.389342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FastText...\n",
      "Docs: 312735\n",
      "Selected words: 159585\n",
      "Processed OOV words: 5518\n",
      "\n",
      "GloVe...\n",
      "Docs: 312735\n",
      "Selected words: 160751\n",
      "Processed OOV words: 5155\n",
      "\n",
      "GloVe Twitter...\n",
      "Docs: 312735\n",
      "Selected words: 129743\n",
      "Processed OOV words: 9465\n"
     ]
    }
   ],
   "source": [
    "max_len = 450\n",
    "\n",
    "print(\"\\nFastText...\")\n",
    "text_analyzer_ft = TextAnalyzer(word2inx_ft, vectors_ft, max_len=max_len, process_oov_words=True, oov_min_doc_hits=5)\n",
    "seq_ft, _ = text_analyzer_ft.fit_on_docs(docs)\n",
    "\n",
    "X_ft = seq_ft[:len(comments)]\n",
    "test_X_ft = seq_ft[len(comments):]\n",
    "\n",
    "print(\"\\nGloVe...\")\n",
    "text_analyzer_gl = TextAnalyzer(word2inx_gl, vectors_gl, max_len=max_len, process_oov_words=True, oov_min_doc_hits=5)\n",
    "seq_gl, _ = text_analyzer_gl.fit_on_docs(docs)\n",
    "\n",
    "X_gl = seq_gl[:len(comments)]\n",
    "test_X_gl = seq_gl[len(comments):]\n",
    "\n",
    "print(\"\\nGloVe Twitter...\")\n",
    "text_analyzer_gl_tw = TextAnalyzer(word2inx_gl_tw, vectors_gl_tw, max_len=max_len, process_oov_words=True, oov_min_doc_hits=5)\n",
    "seq_gl_tw, _ = text_analyzer_gl_tw.fit_on_docs(docs_tw)\n",
    "\n",
    "X_gl_tw = seq_gl_tw[:len(comments)]\n",
    "test_X_gl_tw = seq_gl_tw[len(comments):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:47:21.734635Z",
     "start_time": "2018-03-08T12:47:21.523365Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.stack([X_ft, X_gl, X_gl_tw])\n",
    "test_X = np.stack([test_X_ft, test_X_gl, test_X_gl_tw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:47:22.060891Z",
     "start_time": "2018-03-08T12:47:21.735613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 143613, valid: 15958\n"
     ]
    }
   ],
   "source": [
    "# Train/Valid splitting\n",
    "trn_inx, val_inx = stratified_sampling(Y, 0.1, seed)\n",
    "\n",
    "print(\"train: {}, valid: {}\".format(len(trn_inx), len(val_inx)))\n",
    "# plot_stratified_sampling(Y, trn_inx, val_inx, inx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:47:22.084863Z",
     "start_time": "2018-03-08T12:47:22.061898Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Current exp model\n",
    "def getExpModel(input_shape, classes, num_words, emb_sizes, emb_matrixes, \n",
    "                emb_dropout=0.5, attention=0, dense=False, emb_trainable=False):\n",
    "\n",
    "    x_inputs = []\n",
    "    embs = []\n",
    "    \n",
    "    for i in range(0,len(num_words)):\n",
    "        x_input = Input(shape=(input_shape,))\n",
    "        emb = Embedding(num_words[i], emb_sizes[i], weights=[emb_matrixes[i]], trainable=emb_trainable, name=\"embs_\"+str(i))(x_input)\n",
    "        x_inputs.append(x_input)\n",
    "        embs.append(emb)\n",
    "            \n",
    "    \n",
    "    emb = concatenate(embs)\n",
    "    emb = SpatialDropout1D(emb_dropout)(emb)\n",
    "        \n",
    "    rnn1 = Bidirectional(CuDNNGRU(64, return_sequences=True))(emb)\n",
    "    rnn2 = Bidirectional(CuDNNGRU(64, return_sequences=True))(rnn1)\n",
    "    x = concatenate([rnn1, rnn2])\n",
    "\n",
    "    if attention == 1: x = AttentionWeightedAverage()(x)\n",
    "    elif attention == 2: x = Attention()(x)\n",
    "    else: x = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    if dense: \n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "    \n",
    "    x_output = Dense(classes, activation='sigmoid')(x)\n",
    "    return Model(inputs=x_inputs, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:47:24.002923Z",
     "start_time": "2018-03-08T12:47:22.085717Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 450)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 450)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 450)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embs_0 (Embedding)              (None, 450, 300)     47875500    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embs_1 (Embedding)              (None, 450, 300)     48225300    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embs_2 (Embedding)              (None, 450, 200)     25948600    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 450, 800)     0           embs_0[0][0]                     \n",
      "                                                                 embs_1[0][0]                     \n",
      "                                                                 embs_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 450, 800)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 450, 128)     332544      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 450, 128)     74496       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 450, 256)     0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            1542        global_max_pooling1d_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 122,457,982\n",
      "Trainable params: 408,582\n",
      "Non-trainable params: 122,049,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(toxic.models)\n",
    "# from toxic.models import *\n",
    "\n",
    "model_name = 'exp_comb_model'\n",
    "\n",
    "model = getExpModel(input_shape=max_len, classes=Y.shape[1], \n",
    "                  num_words=[len(text_analyzer_ft.inx2emb), len(text_analyzer_gl.inx2emb), len(text_analyzer_gl_tw.inx2emb)],\n",
    "                  emb_sizes=[text_analyzer_ft.emb_size, text_analyzer_gl.emb_size, text_analyzer_gl_tw.emb_size],\n",
    "                  emb_matrixes=[text_analyzer_ft.emb_vectors, text_analyzer_gl.emb_vectors, text_analyzer_gl_tw.emb_vectors],\n",
    "                  emb_dropout=0.25, attention=0, dense=False, emb_trainable=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:47:24.008085Z",
     "start_time": "2018-03-08T12:47:24.004182Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(models_dir+model_name+'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=1, mode='auto')\n",
    "lr_schedule = LearningRateScheduler(lr_change, verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1, min_lr=0.0001, verbose=1)\n",
    "# tensorboard = TensorBoard(log_dir='logs', write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T12:47:24.205504Z",
     "start_time": "2018-03-08T12:47:24.009310Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "val_batch_size = 1024\n",
    "weights = getClassWeights(Y, mu=0.5)\n",
    "\n",
    "class FeatureManySequence(Sequence):\n",
    "    \n",
    "    def __init__(self, X, Y, batch_size, shuffle=False):\n",
    "        \n",
    "        self.X, self.Y = X, Y\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.inx = np.arange(0, self.Y.shape[0])\n",
    "        self.shuffle = shuffle\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.inx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.inx.shape[0] / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        batch_inx = self.inx[i*self.batch_size:(i+1)*self.batch_size]\n",
    "        \n",
    "        return list(self.X[:, batch_inx]), self.Y[batch_inx]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.inx)\n",
    "\n",
    "trn_seq = FeatureManySequence(X[:,trn_inx], Y[trn_inx], batch_size, shuffle=True)\n",
    "val_seq = FeatureManySequence(X[:,val_inx], Y[val_inx], val_batch_size)\n",
    "roc_auc_eval = RocAucEvaluation(list(X[:,val_inx]), Y[val_inx], batch_size=val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:25.121683Z",
     "start_time": "2018-03-08T12:47:24.206637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "561/561 [==============================] - 104s 186ms/step - loss: 0.1015 - val_loss: 0.0444\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04442, saving model to models/exp_comb_model.h5\n",
      "ROC-AUC: 0.97746925\n",
      "\n",
      "\n",
      "Epoch 2/32\n",
      "561/561 [==============================] - 104s 185ms/step - loss: 0.0435 - val_loss: 0.0407\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04442 to 0.04072, saving model to models/exp_comb_model.h5\n",
      "ROC-AUC: 0.98649338\n",
      "\n",
      "\n",
      "Epoch 3/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0394 - val_loss: 0.0387\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04072 to 0.03873, saving model to models/exp_comb_model.h5\n",
      "ROC-AUC: 0.98960346\n",
      "\n",
      "\n",
      "Epoch 4/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0359 - val_loss: 0.0376\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03873 to 0.03757, saving model to models/exp_comb_model.h5\n",
      "ROC-AUC: 0.99054679\n",
      "\n",
      "\n",
      "Epoch 5/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0344 - val_loss: 0.0377\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "ROC-AUC: 0.99048541\n",
      "\n",
      "\n",
      "Epoch 6/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0346 - val_loss: 0.0380\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "ROC-AUC: 0.99063626\n",
      "\n",
      "\n",
      "Epoch 7/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0336 - val_loss: 0.0379\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "ROC-AUC: 0.99073064\n",
      "\n",
      "\n",
      "Epoch 8/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0308 - val_loss: 0.0381\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "ROC-AUC: 0.99090321\n",
      "\n",
      "\n",
      "Epoch 9/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0293 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "ROC-AUC: 0.99076427\n",
      "\n",
      "\n",
      "Epoch 10/32\n",
      "561/561 [==============================] - 105s 187ms/step - loss: 0.0295 - val_loss: 0.0388\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "ROC-AUC: 0.99052896\n",
      "\n",
      "\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0d4e26668>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=32\n",
    "\n",
    "clr = CyclicLR(base_lr=0.0001, max_lr=0.003, step_size=2*len(trn_seq), mode='triangular2')\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.Nadam())\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=trn_seq, steps_per_epoch=len(trn_seq),\n",
    "    validation_data=val_seq, validation_steps=len(val_seq),\n",
    "    initial_epoch=0, epochs=epochs, shuffle=False, verbose=1,\n",
    "    callbacks=[model_checkpoint, clr, early_stop, roc_auc_eval],\n",
    "#     callbacks=[model_checkpoint, lr_reduce, early_stop, roc_auc_eval],\n",
    "    use_multiprocessing=False, workers=cpu_cores, max_queue_size=8*cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:25.124313Z",
     "start_time": "2018-03-08T13:05:25.122724Z"
    }
   },
   "outputs": [],
   "source": [
    "# matplotlib.rcParams['figure.figsize'] = (24,8)\n",
    "\n",
    "# plt.xlabel('Learning Rate')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.plot(clr.history['lr'], clr.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:26.305344Z",
     "start_time": "2018-03-08T13:05:25.125230Z"
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model(models_dir+model_name+'.h5', compile=True, \n",
    "                   custom_objects={'Attention':Attention, 'AttentionWeightedAverage':AttentionWeightedAverage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:54.734985Z",
     "start_time": "2018-03-08T13:05:26.306314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 0.06960281656512934\n",
      "severe_toxic: 0.019473836328844602\n",
      "obscene: 0.0365750524786678\n",
      "threat: 0.0068126235100814175\n",
      "insult: 0.04887471573575669\n",
      "identity_hate: 0.01620135985454672\n",
      "\n",
      "\n",
      "avg_loss: 0.03292340074550443\n",
      "ROC AUC: 0.9928868517878993\n"
     ]
    }
   ],
   "source": [
    "Y_trn_pred = model.predict(list(X[:,trn_inx]), batch_size=1024, verbose=0)\n",
    "losses = compute_losses(Y[trn_inx], Y_trn_pred, eps=1e-5)\n",
    "for label, label_loss in zip(inx2label, losses):\n",
    "    print(\"{}: {}\".format(label, label_loss))\n",
    "print()\n",
    "\n",
    "trn_loss = sum(losses)/len(losses)\n",
    "trn_auc = metrics.roc_auc_score(Y[trn_inx], Y_trn_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(trn_loss))\n",
    "print(\"ROC AUC: {}\".format(trn_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:57.898839Z",
     "start_time": "2018-03-08T13:05:54.735981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 0.08423508211303908\n",
      "severe_toxic: 0.01992617911071482\n",
      "obscene: 0.04173761610106832\n",
      "threat: 0.007220680647989223\n",
      "insult: 0.05627580592223156\n",
      "identity_hate: 0.016020324807685685\n",
      "\n",
      "\n",
      "avg_loss: 0.03756928145045479\n",
      "ROC AUC: 0.9905467907083395\n"
     ]
    }
   ],
   "source": [
    "Y_val_pred = model.predict(list(X[:,val_inx]), batch_size=1024, verbose=0)\n",
    "losses = compute_losses(Y[val_inx], Y_val_pred, eps=1e-5)\n",
    "for label, label_loss in zip(inx2label, losses):\n",
    "    print(\"{}: {}\".format(label, label_loss))\n",
    "print()\n",
    "\n",
    "val_loss = sum(losses)/len(losses)\n",
    "val_auc = metrics.roc_auc_score(Y[val_inx], Y_val_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(val_loss))\n",
    "print(\"ROC AUC: {}\".format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.047375Z",
     "start_time": "2018-03-08T13:05:57.899787Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.047855Z",
     "start_time": "2018-03-08T12:45:14.683Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs1=epochs+8\n",
    "clr = CyclicLR(base_lr=0.0001, max_lr=0.001, step_size=2*len(trn_seq), mode='triangular2')\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='auto')\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.Adam())\n",
    "# model.compile(loss=art_loss, optimizer=optimizers.Adam())\n",
    "model.fit_generator(\n",
    "    generator=trn_seq, steps_per_epoch=len(trn_seq),\n",
    "    validation_data=val_seq, validation_steps=len(val_seq),\n",
    "    initial_epoch=epochs, epochs=epochs1, shuffle=False, verbose=1,\n",
    "#     class_weight=weights,\n",
    "    callbacks=[model_checkpoint, clr, early_stop, roc_auc_eval],\n",
    "#     callbacks=[model_checkpoint, lr_reduce, early_stop, roc_auc_eval],\n",
    "    use_multiprocessing=False, workers=cpu_cores, max_queue_size=8*cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.048371Z",
     "start_time": "2018-03-08T12:45:14.686Z"
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model(models_dir+model_name+'.h5', compile=True, \n",
    "                   custom_objects={'Attention':Attention, 'AttentionWeightedAverage':AttentionWeightedAverage, 'art_loss':art_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.048868Z",
     "start_time": "2018-03-08T12:45:14.688Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val_pred = model.predict(X[val_inx], batch_size=1024, verbose=0)\n",
    "losses = compute_losses(Y[val_inx], Y_val_pred, eps=1e-5)\n",
    "\n",
    "val_loss = sum(losses)/len(losses)\n",
    "val_auc = metrics.roc_auc_score(Y[val_inx], Y_val_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(val_loss))\n",
    "print(\"ROC AUC: {}\".format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.049335Z",
     "start_time": "2018-03-08T12:45:14.689Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_name = 'exp__focal_loss_a1.0_g0.5__fasttext__d0.3__submission_'+str(round(val_loss, 5))+'_'+str(round(val_auc, 5))+'.csv'\n",
    "\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "test_pred = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "sample_submission[inx2label] = test_pred\n",
    "sample_submission.to_csv(results_dir+submission_name, index=False)\n",
    "\n",
    "FileLink(results_dir+submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.049799Z",
     "start_time": "2018-03-08T12:45:14.691Z"
    }
   },
   "outputs": [],
   "source": [
    "# pseudo\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.050269Z",
     "start_time": "2018-03-08T12:45:14.693Z"
    }
   },
   "outputs": [],
   "source": [
    "model_loss_checkpoint = ModelCheckpoint(models_dir+model_name+'_pseudo.h5', monitor='val_loss', verbose=1, mode='min', save_best_only=True)\n",
    "model.compile(optimizer=optimizers.Nadam(0.0001), loss='binary_crossentropy')\n",
    "\n",
    "ps_epochs = 3\n",
    "for ps_inx in range(0, ps_epochs):  \n",
    "    test_Y = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "    \n",
    "    trn_ps_seq = PseudoFeatureSequence(X[trn_inx], X_meta[trn_inx], Y[trn_inx], 182, \n",
    "                                       test_X, np.zeros((test_X.shape[0], 2)), test_Y, 74,  \n",
    "                                       shuffle=True)\n",
    "    model.fit_generator(\n",
    "        generator=trn_ps_seq, steps_per_epoch=len(trn_ps_seq),  \n",
    "        validation_data=val_seq, validation_steps=len(val_seq),\n",
    "        initial_epoch=epochs+ps_inx, epochs=epochs+ps_inx+1, \n",
    "        shuffle=False, verbose=1,\n",
    "        class_weight=weights,\n",
    "        callbacks=[model_loss_checkpoint, roc_auc_eval],\n",
    "        use_multiprocessing=False, workers=cpu_cores, max_queue_size=4*cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.050773Z",
     "start_time": "2018-03-08T12:45:14.695Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val_pred = model.predict(X[val_inx], batch_size=512, verbose=0)\n",
    "losses = compute_losses(Y[val_inx], Y_val_pred, eps=1e-5)\n",
    "\n",
    "val_loss = sum(losses)/len(losses)\n",
    "val_auc = metrics.roc_auc_score(Y[val_inx], Y_val_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(val_loss))\n",
    "print(\"ROC AUC: {}\".format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T13:05:58.051337Z",
     "start_time": "2018-03-08T12:45:14.698Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_name = 'fasttext__gru__max_pool2d__submission_'+str(round(val_loss, 5))+'_'+str(round(val_auc, 5))+'_pseudo'+ps_epochs+'.csv'\n",
    "\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "test_pred = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "sample_submission[inx2label] = test_pred\n",
    "sample_submission.to_csv(results_dir+submission_name, index=False)\n",
    "\n",
    "FileLink(results_dir+submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
