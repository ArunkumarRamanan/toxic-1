{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:52:40.445586Z",
     "start_time": "2018-02-22T15:52:38.806809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7961730\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# import local_utils; importlib.reload(local_utils)\n",
    "from local_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:52:44.395669Z",
     "start_time": "2018-02-22T15:52:40.447178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "ids, comments, Y, test_ids, test_comments, inx2label, label2inx = load_data()\n",
    "Y_wblank = np.concatenate([Y, np.expand_dims((~Y.any(axis=1)).astype(int), 1)], axis=1)\n",
    "\n",
    "comments = Parallel(n_jobs=cpu_cores)(delayed(preprocess)(text) for text in comments)\n",
    "test_comments = Parallel(n_jobs=cpu_cores)(delayed(preprocess)(text) for text in test_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:52:47.219937Z",
     "start_time": "2018-02-22T15:52:44.397512Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "max_len = 450\n",
    "vectors, inx2word, word2inx = load_embs()\n",
    "text_analyzer = TextAnalyzer(word2inx, vectors, process_oov_words=True, oov_min_doc_hits=5, max_len=max_len, cpu_cores=cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:53:49.888891Z",
     "start_time": "2018-02-22T15:52:47.221040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 312735\n",
      "Selected words: 154006\n",
      "Processed OOV words: 8451\n",
      "mean_len: 77.40685244695989\n",
      "mean_len + 2*std: 316.8939801273775\n",
      "mean_len + 3*std: 436.63754396758634\n"
     ]
    }
   ],
   "source": [
    "seq, meta = text_analyzer.fit_on_texts(comments + test_comments)\n",
    "\n",
    "X = seq[:len(comments)]\n",
    "test_X = seq[len(comments):]\n",
    "\n",
    "meta_mean = meta.mean(axis=0)\n",
    "meta_std = meta.std(axis=0)\n",
    "meta = (meta - meta_mean)/meta_std\n",
    "\n",
    "print(\"mean_len: {}\".format(meta_mean[0]))\n",
    "print(\"mean_len + 2*std: {}\".format(meta_mean[0]+2*meta_std[0]))\n",
    "print(\"mean_len + 3*std: {}\".format(meta_mean[0]+3*meta_std[0]))\n",
    "\n",
    "X_meta = meta[:len(comments)]\n",
    "test_X_meta = meta[len(comments):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:53:50.196893Z",
     "start_time": "2018-02-22T15:53:49.889921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 143613, valid: 15958\n"
     ]
    }
   ],
   "source": [
    "# Train/Valid splitting\n",
    "trn_inx, val_inx = stratified_sampling(Y, 0.1, seed)\n",
    "\n",
    "print(\"train: {}, valid: {}\".format(len(trn_inx), len(val_inx)))\n",
    "# plot_stratified_sampling(Y, trn_inx, val_inx, inx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:53:50.201899Z",
     "start_time": "2018-02-22T15:53:50.197930Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "# def cnn_block(x, filters, kernel_size, attention=0):\n",
    "#     cnn = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(x)\n",
    "    \n",
    "#     if attention == 0: cnn = GlobalMaxPooling1D()(cnn)\n",
    "#     elif attention == 1: cnn = AttentionWeightedAverage()(cnn)\n",
    "#     elif attention == 2: cnn = Attention()(cnn)\n",
    "\n",
    "#     return cnn\n",
    "\n",
    "# def getCNNModel(input_shape, classes, num_words, emb_size, emb_matrix,\n",
    "#                 attention=0, dense=False, emb_trainable=False):\n",
    "\n",
    "#     x_input = Input(shape=(input_shape,))\n",
    "    \n",
    "#     emb = Embedding(num_words, emb_size, weights=[emb_matrix], trainable=emb_trainable, name='embs')(x_input)\n",
    "#     emb = SpatialDropout1D(0.15)(emb)\n",
    "        \n",
    "#     cnn1 = cnn_block(emb, 100, 3, attention=attention)\n",
    "#     cnn2 = cnn_block(emb, 100, 4, attention=attention)\n",
    "#     cnn3 = cnn_block(emb, 100, 5, attention=attention)\n",
    "#     x = concatenate([cnn1, cnn2, cnn3])\n",
    "\n",
    "#     x = Dropout(0.15)(x)\n",
    "    \n",
    "#     if dense: \n",
    "#         x = Dense(50, activation='relu')(x)\n",
    "#         x = Dropout(0.15)(x)\n",
    "    \n",
    "#     x_output = Dense(classes, activation='sigmoid')(x)\n",
    "#     return Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:53:50.222967Z",
     "start_time": "2018-02-22T15:53:50.202766Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# LSTM-CNN\n",
    "def getLSTMCNNModel(input_shape, classes, num_words, emb_size, emb_matrix,\n",
    "                    attention=0, dense=False, emb_trainable=False):\n",
    "\n",
    "    x_input = Input(shape=(input_shape,))\n",
    "\n",
    "    emb = Embedding(num_words, emb_size, weights=[emb_matrix], trainable=emb_trainable, name='embs')(x_input)\n",
    "    emb = SpatialDropout1D(0.3)(emb)\n",
    "    \n",
    "    rnn = Bidirectional(CuDNNGRU(64, return_sequences=True))(emb)\n",
    "    \n",
    "    cnn1 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(rnn)\n",
    "#     cnn2 = Conv1D(filters=64, kernel_size=4, activation='relu', padding='same')(rnn)\n",
    "#     cnn3 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(rnn)\n",
    "#     cnn4 = Conv1D(filters=64, kernel_size=6, activation='relu', padding='same')(rnn)\n",
    "    \n",
    "    x = cnn1\n",
    "#     x = concatenate([cnn1, cnn2, cnn3, cnn4])\n",
    "    \n",
    "    if attention == 1: x = AttentionWeightedAverage()(x)\n",
    "    elif attention == 2: x = Attention()(x)\n",
    "    else: x = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    if dense: \n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "    \n",
    "    x_output = Dense(classes, activation='sigmoid')(x)\n",
    "    return Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:53:50.247026Z",
     "start_time": "2018-02-22T15:53:50.223824Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# CNN-LSTM\n",
    "def getCNNLSTMModel(input_shape, classes, num_words, emb_size, emb_matrix,\n",
    "                    attention=0, dense=False, emb_trainable=False):\n",
    "\n",
    "    x_input = Input(shape=(input_shape,))\n",
    "\n",
    "    emb = Embedding(num_words, emb_size, weights=[emb_matrix], trainable=emb_trainable, name='embs')(x_input)\n",
    "    emb = SpatialDropout1D(0.3)(emb)\n",
    "#     rnn = SpatialDropout1D(0.15)(rnn)\n",
    "    \n",
    "    cnn1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(emb)\n",
    "    cnn2 = Conv1D(filters=64, kernel_size=4, activation='relu', padding='same')(emb)\n",
    "    cnn3 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(emb)\n",
    "#     cnn4 = Conv1D(filters=64, kernel_size=6, activation='relu', padding='same')(emb)\n",
    "    \n",
    "    x = concatenate([cnn1, cnn2, cnn3])\n",
    "    x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "    \n",
    "    if attention == 1: x = AttentionWeightedAverage()(x)\n",
    "    elif attention == 2: x = Attention()(x)\n",
    "    else: x = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    if dense: \n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "    \n",
    "    x_output = Dense(classes, activation='sigmoid')(x)\n",
    "    return Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T15:53:50.270175Z",
     "start_time": "2018-02-22T15:53:50.247982Z"
    },
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# MaxPool2D\n",
    "def getBiCuDNNGRUMaxPool2DModel(input_shape, classes, num_words, emb_size, emb_matrix,\n",
    "                                attention=0, dense=False, emb_trainable=False):\n",
    "\n",
    "    x_input = Input(shape=(input_shape,))\n",
    "    \n",
    "    emb = Embedding(num_words, emb_size, weights=[emb_matrix], trainable=emb_trainable, name='embs')(x_input)\n",
    "    emb = SpatialDropout1D(0.5)(emb)\n",
    "    \n",
    "    x = Bidirectional(CuDNNGRU(250, return_sequences=True))(emb)\n",
    "#     rnn1 = Bidirectional(CuDNNGRU(100, return_sequences=True))(emb)\n",
    "#     rnn2 = Bidirectional(CuDNNGRU(100, return_sequences=True))(rnn1)\n",
    "#     x = concatenate([rnn1, rnn2])\n",
    "\n",
    "    if attention == 1: x1 = AttentionWeightedAverage()(x)\n",
    "    elif attention == 2: x1 = Attention()(x)\n",
    "    else: x1 = GlobalMaxPooling1D()(x)\n",
    "        \n",
    "    if attention == 1: x2 = AttentionWeightedAverage()(Permute((2, 1))(x))\n",
    "    elif attention == 2: x2 = Attention()(Permute((2, 1))(x))\n",
    "    else: x2 = GlobalMaxPooling1D()(Permute((2, 1))(x))\n",
    "        \n",
    "    x = concatenate([x1, x2])\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    if dense: \n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "    \n",
    "    x_output = Dense(classes, activation='sigmoid')(x)\n",
    "    return Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:40:55.618042Z",
     "start_time": "2018-02-22T16:40:55.600209Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBiCuDNNGRUx2Model1(input_shape, classes, num_words, emb_size, emb_matrix,\n",
    "                         attention=0, dense=False, emb_trainable=False):\n",
    "\n",
    "    x_input = Input(shape=(input_shape,))\n",
    "    \n",
    "    emb = Embedding(num_words, emb_size, weights=[emb_matrix], trainable=emb_trainable, name='embs')(x_input)\n",
    "    emb = SpatialDropout1D(0.3)(emb)\n",
    "        \n",
    "    rnn1 = Bidirectional(CuDNNGRU(64, return_sequences=True))(emb)\n",
    "    rnn2 = Bidirectional(CuDNNGRU(64, return_sequences=True))(rnn1)\n",
    "    x = concatenate([rnn1, rnn2])\n",
    "\n",
    "    if attention == 1: x = AttentionWeightedAverage()(x)\n",
    "    elif attention == 2: x = Attention()(x)\n",
    "    else: x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    \n",
    "    if dense: \n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "    \n",
    "    x_output = Dense(classes, activation='sigmoid')(x)\n",
    "    return Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:40:56.574549Z",
     "start_time": "2018-02-22T16:40:56.136773Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 450)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embs (Embedding)                (None, 450, 300)     46201800    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 450, 300)     0           embs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 450, 128)     140544      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 450, 128)     74496       bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 450, 256)     0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            1542        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 46,418,382\n",
      "Trainable params: 216,582\n",
      "Non-trainable params: 46,201,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(toxic.models)\n",
    "# from toxic.models import *\n",
    "\n",
    "model_name = 'exp_model'\n",
    "model = getBiCuDNNGRUx2Model1(input_shape=X.shape[1], classes=Y.shape[1], num_words=len(text_analyzer.inx2emb), \n",
    "                             emb_size=text_analyzer.emb_size, emb_matrix=text_analyzer.emb_vectors,\n",
    "                             attention=0, dense=False, emb_trainable=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:40:59.036373Z",
     "start_time": "2018-02-22T16:40:59.024167Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(models_dir+model_name+'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "clr = CyclicLR()\n",
    "lr_schedule = LearningRateScheduler(lr_change, verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1, min_lr=0.0001, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=1, mode='auto')\n",
    "roc_auc_eval = RocAucEvaluation(X[val_inx], Y[val_inx], batch_size=512)\n",
    "# tensorboard = TensorBoard(log_dir='logs', write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:40:59.378191Z",
     "start_time": "2018-02-22T16:40:59.299639Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "weights = getClassWeights(Y, mu=0.5)\n",
    "\n",
    "# trn_seq = StratifiedFeatureSequence(X[trn_inx], Y[trn_inx], batch_size)\n",
    "trn_seq = FeatureSequence(X[trn_inx], X_meta[trn_inx], Y[trn_inx], batch_size, shuffle=True)\n",
    "val_seq = FeatureSequence(X[val_inx], X_meta[val_inx], Y[val_inx], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:40:59.964512Z",
     "start_time": "2018-02-22T16:40:59.948260Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.RMSprop())\n",
    "# model.compile(loss=art_loss, optimizer=optimizers.RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T17:27:13.227652Z",
     "start_time": "2018-02-22T16:41:01.095164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0707 - val_loss: 0.0507\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05074, saving model to models/exp_model.h5\n",
      "ROC-AUC: 0.97852154\n",
      "Epoch 2/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0501 - val_loss: 0.0429\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05074 to 0.04286, saving model to models/exp_model.h5\n",
      "ROC-AUC: 0.98519829\n",
      "Epoch 3/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0470 - val_loss: 0.0419\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04286 to 0.04193, saving model to models/exp_model.h5\n",
      "ROC-AUC: 0.98635180\n",
      "Epoch 4/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0448 - val_loss: 0.0399\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04193 to 0.03994, saving model to models/exp_model.h5\n",
      "ROC-AUC: 0.98845531\n",
      "Epoch 5/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0432 - val_loss: 0.0406\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "ROC-AUC: 0.98881276\n",
      "Epoch 6/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0417 - val_loss: 0.0392\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03994 to 0.03922, saving model to models/exp_model.h5\n",
      "ROC-AUC: 0.98955647\n",
      "Epoch 7/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0408 - val_loss: 0.0384\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03922 to 0.03836, saving model to models/exp_model.h5\n",
      "ROC-AUC: 0.98915780\n",
      "Epoch 8/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0402 - val_loss: 0.0401\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "ROC-AUC: 0.98986456\n",
      "Epoch 9/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0395 - val_loss: 0.0385\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "ROC-AUC: 0.99029311\n",
      "Epoch 10/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0389 - val_loss: 0.0383\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03836 to 0.03829, saving model to models/exp_model.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "ROC-AUC: 0.99027745\n",
      "Epoch 11/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0377 - val_loss: 0.0389\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "ROC-AUC: 0.99014791\n",
      "Epoch 12/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0374 - val_loss: 0.0379\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03829 to 0.03790, saving model to models/exp_model.h5\n",
      "ROC-AUC: 0.99029717\n",
      "Epoch 13/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0368 - val_loss: 0.0385\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "ROC-AUC: 0.99015902\n",
      "Epoch 14/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0365 - val_loss: 0.0385\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "ROC-AUC: 0.99027419\n",
      "Epoch 15/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0362 - val_loss: 0.0394\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "ROC-AUC: 0.99001256\n",
      "Epoch 16/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0355 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "ROC-AUC: 0.99038285\n",
      "Epoch 17/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0352 - val_loss: 0.0380\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "ROC-AUC: 0.99033300\n",
      "Epoch 18/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0346 - val_loss: 0.0395\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "ROC-AUC: 0.99020644\n",
      "Epoch 19/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0344 - val_loss: 0.0387\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "ROC-AUC: 0.99011485\n",
      "Epoch 20/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0341 - val_loss: 0.0392\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "ROC-AUC: 0.99016302\n",
      "Epoch 21/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0336 - val_loss: 0.0388\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "ROC-AUC: 0.99014778\n",
      "Epoch 22/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0332 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "ROC-AUC: 0.99019673\n",
      "Epoch 23/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0328 - val_loss: 0.0389\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "ROC-AUC: 0.98998662\n",
      "Epoch 24/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0327 - val_loss: 0.0402\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "ROC-AUC: 0.98985814\n",
      "Epoch 25/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0324 - val_loss: 0.0392\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "ROC-AUC: 0.99010316\n",
      "Epoch 26/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0322 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "ROC-AUC: 0.99025095\n",
      "Epoch 27/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0321 - val_loss: 0.0394\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "ROC-AUC: 0.99017499\n",
      "Epoch 28/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0320 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "ROC-AUC: 0.99006214\n",
      "Epoch 29/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0318 - val_loss: 0.0397\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "ROC-AUC: 0.99015101\n",
      "Epoch 30/30\n",
      "561/561 [==============================] - 90s 160ms/step - loss: 0.0315 - val_loss: 0.0398\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "ROC-AUC: 0.99009897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76260a9240>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=30\n",
    "model.fit_generator(\n",
    "    generator=trn_seq, steps_per_epoch=len(trn_seq),\n",
    "    validation_data=val_seq, validation_steps=len(val_seq),\n",
    "    initial_epoch=0, epochs=epochs, shuffle=False, verbose=1,\n",
    "    class_weight=weights,\n",
    "#     callbacks=[model_checkpoint, clr, early_stop, roc_auc_eval],\n",
    "    callbacks=[model_checkpoint, lr_reduce, roc_auc_eval],\n",
    "    use_multiprocessing=False, workers=cpu_cores, max_queue_size=8*cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T18:05:57.184563Z",
     "start_time": "2018-02-22T18:05:56.093379Z"
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model(models_dir+model_name+'.h5', compile=True, \n",
    "                   custom_objects={'Attention':Attention, 'AttentionWeightedAverage':AttentionWeightedAverage, 'art_loss':art_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T18:05:59.320440Z",
     "start_time": "2018-02-22T18:05:57.185531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "avg_loss: 0.037904791718368976\n",
      "ROC AUC: 0.9902971652562657\n"
     ]
    }
   ],
   "source": [
    "Y_val_pred = model.predict(X[val_inx], batch_size=1024, verbose=0)\n",
    "losses = compute_losses(Y[val_inx], Y_val_pred, eps=1e-5)\n",
    "\n",
    "val_loss = sum(losses)/len(losses)\n",
    "val_auc = metrics.roc_auc_score(Y[val_inx], Y_val_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(val_loss))\n",
    "print(\"ROC AUC: {}\".format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:26:13.412288Z",
     "start_time": "2018-02-22T16:26:13.284097Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:26:13.412786Z",
     "start_time": "2018-02-22T15:52:38.828Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_name = 'fasttext__base_model__clr__art_loss_p1.0__nadam__512str_bs__weights0.5__submission_'+str(round(val_loss, 5))+'_'+str(round(val_auc, 5))+'.csv'\n",
    "\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "test_pred = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "sample_submission[inx2label] = test_pred\n",
    "sample_submission.to_csv(results_dir+submission_name, index=False)\n",
    "\n",
    "FileLink(results_dir+submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:26:13.413294Z",
     "start_time": "2018-02-22T15:52:38.830Z"
    }
   },
   "outputs": [],
   "source": [
    "# pseudo\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:26:13.413854Z",
     "start_time": "2018-02-22T15:52:38.832Z"
    }
   },
   "outputs": [],
   "source": [
    "model_loss_checkpoint = ModelCheckpoint(models_dir+model_name+'_pseudo.h5', monitor='val_loss', verbose=1, mode='min', save_best_only=True)\n",
    "model.compile(optimizer=optimizers.RMSprop(0.0001), loss='binary_crossentropy', metrics=[auc_roc])\n",
    "\n",
    "ps_epochs = 3\n",
    "for ps_inx in range(0, ps_epochs):  \n",
    "    test_Y = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "    \n",
    "    trn_ps_seq = PseudoFeatureSequence(X[trn_inx], X_meta[trn_inx], Y[trn_inx], 182, \n",
    "                                       test_X, np.zeros((test_X.shape[0], 2)), test_Y, 74,  \n",
    "                                       shuffle=True)\n",
    "    model.fit_generator(\n",
    "        generator=trn_ps_seq, steps_per_epoch=len(trn_ps_seq),  \n",
    "        validation_data=val_seq, validation_steps=len(val_seq),\n",
    "        initial_epoch=epochs+ps_inx, epochs=epochs+ps_inx+1, \n",
    "        shuffle=False, verbose=1,\n",
    "        class_weight=weights,\n",
    "        callbacks=[model_loss_checkpoint],\n",
    "        use_multiprocessing=False, workers=cpu_cores, max_queue_size=4*cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:26:13.414346Z",
     "start_time": "2018-02-22T15:52:38.834Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val_pred = model.predict(X[val_inx], batch_size=512, verbose=0)\n",
    "losses = compute_losses(Y[val_inx], Y_val_pred, eps=1e-5)\n",
    "\n",
    "val_loss = sum(losses)/len(losses)\n",
    "val_auc = metrics.roc_auc_score(Y[val_inx], Y_val_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(val_loss))\n",
    "print(\"ROC AUC: {}\".format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T16:26:13.414883Z",
     "start_time": "2018-02-22T15:52:38.836Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_name = 'fasttext__gru__max_pool2d__submission_'+str(round(val_loss, 5))+'_'+str(round(val_auc, 5))+'_pseudo'+ps_epochs+'.csv'\n",
    "\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "test_pred = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "sample_submission[inx2label] = test_pred\n",
    "sample_submission.to_csv(results_dir+submission_name, index=False)\n",
    "\n",
    "FileLink(results_dir+submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
