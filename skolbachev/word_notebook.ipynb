{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T08:44:23.854521Z",
     "start_time": "2018-02-19T08:44:22.003917Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/deepl/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Seed: 7961730\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# import local_utils; importlib.reload(local_utils)\n",
    "from local_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T08:44:27.864628Z",
     "start_time": "2018-02-19T08:44:23.855546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "ids, comments, Y, test_ids, test_comments, inx2label, label2inx = load_data()\n",
    "Y_wblank = np.concatenate([Y, np.expand_dims((~Y.any(axis=1)).astype(int), 1)], axis=1)\n",
    "\n",
    "comments = Parallel(n_jobs=cpu_cores)(delayed(preprocess)(text) for text in comments)\n",
    "test_comments = Parallel(n_jobs=cpu_cores)(delayed(preprocess)(text) for text in test_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T08:44:30.456537Z",
     "start_time": "2018-02-19T08:44:27.866223Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "max_len = 450\n",
    "vectors, inx2word, word2inx = load_embs()\n",
    "text_analyzer = TextAnalyzer(word2inx, vectors, process_oov_words=True, oov_min_doc_hits=5, max_len=max_len, cpu_cores=cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T08:45:33.272917Z",
     "start_time": "2018-02-19T08:44:30.459971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 312735\n",
      "Selected words: 154006\n",
      "Processed OOV words: 8451\n",
      "mean_len + 2*std 316.8939801273775\n",
      "mean_len + 3*std 436.63754396758634\n"
     ]
    }
   ],
   "source": [
    "seq, meta = text_analyzer.fit_on_texts(comments + test_comments)\n",
    "\n",
    "X = seq[:len(comments)]\n",
    "test_X = seq[len(comments):]\n",
    "\n",
    "meta_mean = meta.mean(axis=0)\n",
    "meta_std = meta.std(axis=0)\n",
    "meta = (meta - meta_mean)/meta_std\n",
    "\n",
    "print(\"mean_len + 2*std: {}\".format(meta_mean[0]+2*meta_std[0]))\n",
    "print(\"mean_len + 3*std: {}\".format(meta_mean[0]+3*meta_std[0]))\n",
    "\n",
    "X_meta = meta[:len(comments)]\n",
    "test_X_meta = meta[len(comments):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:28:49.935494Z",
     "start_time": "2018-02-18T16:28:49.622253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 143613, valid: 15958\n"
     ]
    }
   ],
   "source": [
    "# Train/Valid splitting\n",
    "trn_inx, val_inx = stratified_sampling(Y, 0.1, seed)\n",
    "\n",
    "print(\"train: {}, valid: {}\".format(len(trn_inx), len(val_inx)))\n",
    "# plot_stratified_sampling(Y, trn_inx, val_inx, inx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:28:49.941246Z",
     "start_time": "2018-02-18T16:28:49.936904Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "# def cnn_block(x, filters, kernel_size, attention=0):\n",
    "#     cnn = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(x)\n",
    "    \n",
    "#     if attention == 0: cnn = GlobalMaxPooling1D()(cnn)\n",
    "#     elif attention == 1: cnn = AttentionWeightedAverage()(cnn)\n",
    "#     elif attention == 2: cnn = Attention()(cnn)\n",
    "\n",
    "#     return cnn\n",
    "\n",
    "# def getCNNModel(input_shape, classes, num_words, emb_size, emb_matrix,\n",
    "#                 attention=0, dense=False, emb_trainable=False):\n",
    "\n",
    "#     x_input = Input(shape=(input_shape,))\n",
    "    \n",
    "#     emb = Embedding(num_words, emb_size, weights=[emb_matrix], trainable=emb_trainable, name='embs')(x_input)\n",
    "#     emb = SpatialDropout1D(0.15)(emb)\n",
    "        \n",
    "#     cnn1 = cnn_block(emb, 100, 3, attention=attention)\n",
    "#     cnn2 = cnn_block(emb, 100, 4, attention=attention)\n",
    "#     cnn3 = cnn_block(emb, 100, 5, attention=attention)\n",
    "#     x = concatenate([cnn1, cnn2, cnn3])\n",
    "\n",
    "#     x = Dropout(0.15)(x)\n",
    "    \n",
    "#     if dense: \n",
    "#         x = Dense(50, activation='relu')(x)\n",
    "#         x = Dropout(0.15)(x)\n",
    "    \n",
    "#     x_output = Dense(classes, activation='sigmoid')(x)\n",
    "#     return Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:45:29.305032Z",
     "start_time": "2018-02-18T16:45:28.887337Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "embs (Embedding)             (None, 450, 300)          46201800  \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 448, 128)          115328    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 224, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 224, 128)          74496     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 46,392,398\n",
      "Trainable params: 190,598\n",
      "Non-trainable params: 46,201,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(toxic.models)\n",
    "# from toxic.models import *\n",
    "\n",
    "model_name = 'fasttext_model'\n",
    "model = getBiCuDNNGRUx2Model(input_shape=X.shape[1], classes=Y.shape[1], num_words=len(text_analyzer.inx2emb), \n",
    "                             emb_size=text_analyzer.emb_size, emb_matrix=text_analyzer.emb_vectors,\n",
    "                             attention=0, dense=False, emb_trainable=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:45:29.797643Z",
     "start_time": "2018-02-18T16:45:29.785906Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(models_dir+model_name+'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "lr_schedule = LearningRateScheduler(lr_change, verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=1, min_lr=0.0001, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard(log_dir='logs', write_graph=False)\n",
    "roc_auc_callback = ROCAUCCallback(X[val_inx], Y[val_inx], 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:45:30.587604Z",
     "start_time": "2018-02-18T16:45:30.541283Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "weights = getClassWeights(Y)\n",
    "\n",
    "# trn_seq = StratifiedFeatureSequence(X[trn_inx], Y[trn_inx], batch_size)\n",
    "trn_seq = FeatureSequence(X[trn_inx], X_meta[trn_inx], Y[trn_inx], batch_size, shuffle=True)\n",
    "val_seq = FeatureSequence(X[val_inx], X_meta[val_inx], Y[val_inx], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:45:31.039372Z",
     "start_time": "2018-02-18T16:45:31.021736Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())\n",
    "# model.compile(loss=roc_auc_loss, optimizer=optimizers.RMSprop(0.003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:48:04.589329Z",
     "start_time": "2018-02-18T16:45:32.321549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "561/561 [==============================] - 30s 53ms/step - loss: 0.0806 - val_loss: 0.0492\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04920, saving model to models/fasttext_model.h5\n",
      "roc-auc_val: 0.97399145                                                                                                    \n",
      "Epoch 2/5\n",
      "561/561 [==============================] - 29s 52ms/step - loss: 0.0490 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04920 to 0.04599, saving model to models/fasttext_model.h5\n",
      "roc-auc_val: 0.98149839                                                                                                    \n",
      "Epoch 3/5\n",
      "561/561 [==============================] - 29s 52ms/step - loss: 0.0448 - val_loss: 0.0433\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04599 to 0.04329, saving model to models/fasttext_model.h5\n",
      "roc-auc_val: 0.98542972                                                                                                    \n",
      "Epoch 4/5\n",
      "561/561 [==============================] - 29s 52ms/step - loss: 0.0423 - val_loss: 0.0427\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04329 to 0.04274, saving model to models/fasttext_model.h5\n",
      "roc-auc_val: 0.98678243                                                                                                    \n",
      "Epoch 5/5\n",
      "561/561 [==============================] - 29s 52ms/step - loss: 0.0401 - val_loss: 0.0430\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "roc-auc_val: 0.98747                                                                                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f696f24b0f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=5\n",
    "model.fit_generator(\n",
    "    generator=trn_seq, steps_per_epoch=len(trn_seq),\n",
    "    validation_data=val_seq, validation_steps=len(val_seq),\n",
    "    initial_epoch=0, epochs=epochs, shuffle=False, verbose=1,\n",
    "#     class_weight=weights,\n",
    "    callbacks=[model_checkpoint, lr_reduce, early_stop, roc_auc_callback],\n",
    "    use_multiprocessing=False, workers=cpu_cores, max_queue_size=8*cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.773439Z",
     "start_time": "2018-02-18T16:27:38.631Z"
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model(models_dir+model_name+'_loss.h5', compile=True, \n",
    "                   custom_objects={'Attention':Attention, 'AttentionWeightedAverage':AttentionWeightedAverage, \n",
    "                                   'focal_loss':focal_loss, 'roc_auc_loss':roc_auc_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.773914Z",
     "start_time": "2018-02-18T16:27:38.632Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val_pred = model.predict(X[val_inx], batch_size=1024, verbose=0)\n",
    "losses = compute_losses(Y[val_inx], Y_val_pred, eps=1e-5)\n",
    "\n",
    "val_loss = sum(losses)/len(losses)\n",
    "val_auc = metrics.roc_auc_score(Y[val_inx], Y_val_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(val_loss))\n",
    "print(\"ROC AUC: {}\".format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.774381Z",
     "start_time": "2018-02-18T16:27:38.634Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.774849Z",
     "start_time": "2018-02-18T16:27:38.636Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_name = 'fasttext_submission_'+str(round(val_loss, 5))+'_'+str(round(val_auc, 5))+'.csv'\n",
    "\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "test_pred = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "sample_submission[inx2label] = test_pred\n",
    "sample_submission.to_csv(results_dir+submission_name, index=False)\n",
    "\n",
    "FileLink(results_dir+submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.775421Z",
     "start_time": "2018-02-18T16:27:38.637Z"
    }
   },
   "outputs": [],
   "source": [
    "# pseudo\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.775923Z",
     "start_time": "2018-02-18T16:27:38.639Z"
    }
   },
   "outputs": [],
   "source": [
    "model_loss_checkpoint = ModelCheckpoint(models_dir+model_name+'_pseudo.h5', monitor='val_loss', verbose=1, mode='min', save_best_only=True)\n",
    "model.compile(optimizer=optimizers.RMSprop(0.0001), loss='binary_crossentropy', metrics=[auc_roc])\n",
    "\n",
    "ps_epochs = 3\n",
    "for ps_inx in range(0, ps_epochs):  \n",
    "    test_Y = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "    \n",
    "    trn_ps_seq = PseudoFeatureSequence(X[trn_inx], X_meta[trn_inx], Y[trn_inx], 182, \n",
    "                                       test_X, np.zeros((test_X.shape[0], 2)), test_Y, 74,  \n",
    "                                       shuffle=True)\n",
    "    model.fit_generator(\n",
    "        generator=trn_ps_seq, steps_per_epoch=len(trn_ps_seq),  \n",
    "        validation_data=val_seq, validation_steps=len(val_seq),\n",
    "        initial_epoch=epochs+ps_inx, epochs=epochs+ps_inx+1, \n",
    "        shuffle=False, verbose=1,\n",
    "        class_weight=weights,\n",
    "        callbacks=[model_loss_checkpoint],\n",
    "        use_multiprocessing=False, workers=cpu_cores, max_queue_size=4*cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.776433Z",
     "start_time": "2018-02-18T16:27:38.642Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val_pred = model.predict(X[val_inx], batch_size=512, verbose=0)\n",
    "losses = compute_losses(Y[val_inx], Y_val_pred, eps=1e-5)\n",
    "\n",
    "val_loss = sum(losses)/len(losses)\n",
    "val_auc = metrics.roc_auc_score(Y[val_inx], Y_val_pred)\n",
    "\n",
    "print()\n",
    "print(\"avg_loss: {}\".format(val_loss))\n",
    "print(\"ROC AUC: {}\".format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T16:39:35.776908Z",
     "start_time": "2018-02-18T16:27:38.643Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_name = 'fasttext_submission_'+str(round(val_loss, 5))+'_'+str(round(val_auc, 5))+'_pseudo'+ps_epochs+'.csv'\n",
    "\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "test_pred = model.predict(test_X, batch_size=1024, verbose=1)\n",
    "sample_submission[inx2label] = test_pred\n",
    "sample_submission.to_csv(results_dir+submission_name, index=False)\n",
    "\n",
    "FileLink(results_dir+submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
